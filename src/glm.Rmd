---
title: "glm"
author: "Ilpo Arminen"
date: "8/21/2019"
output: github_document
---
This code is based on https://github.com/FRCBS/iron_levels_of_blood_donors script https://github.com/FRCBS/iron_levels_of_blood_donors/blob/master/src/index.Rmd by Muriel Lobier and published in https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0220862 

```{r}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(viridis)
library(stargazer)
library(ggfortify)
library(car)
library(MASS)
library(relaimpo)
library(broom)
library(AER)
library(robustbase)
library(modelr)
library(caret)
```


```{r}
load("/home/ilpo/Paavo/data/modified_data.RData")
```

```{r}
 sum(modified_data$nb_fixed_donations_per_zip)
sum(modified_data$nb_fixed_donors_per_zip)
  
```


  standardization:
   * All  variables are centered only. They are not standardized to increase interpretability of the coefficients.
   * They are not standardized also to highight that using std coeffs does not enable comparison between groups as SDs of different groups are different.  
```{r}
data <- modified_data %>% mutate(higher_education= scale(proportion_inhabitants_with_higher_education,scale=FALSE)[,1],
                eligible_population= scale(eligible_population,scale=FALSE)[,1],
                medianincome = scale(medianincome,scale=FALSE)[,1],
                minDistkm. = scale((minDistkm),scale=FALSE)[,1])
              
```
   # Making regression model for new donors and repeated donors separately 
   # Poisson and negative binomial regression 


```{r,warning=FALSE} 
repeat_dn.poisson <- glm(prop_repeat_donors ~ medianincome + higher_education + eligible_population + minDistkm, data=modified_data,family=poisson)  #repeated donors
new_dn.poisson <- glm(prop_new_donors ~ medianincome + higher_education + eligible_population + minDistkm, data=data, family=poisson)#new donors
```


```{r, warning=FALSE} 
# Lets make binomial model for comparison 
#repeat_dn.negabin <- MASS::glm.nb(prop_repea_tdonors ~ medianincome + higher_education + eligible_population + minDistkm, data=data)
#new_dn.negabin<-MASS::glm.nb(prop_new_donors ~ medianincome + higher_education + eligible_population + minDistkm, data=data)

#quasipoisson
repeat_dn.qpoisson <- glm(prop_repeat_donors ~ medianincome + higher_education + eligible_population + minDistkm, data=data,family=quasipoisson)  
new_dn.qpoisson <- glm(prop_new_donors ~ medianincome + higher_education + eligible_population + minDistkm, data=data, family=quasipoisson)

```



#Repeat donor autoplots
#Poisson

```{r}
autoplot(repeat_dn.poisson,which = 1:6, ncol = 3, label.size = 3,shape = 1, alpha = 0.7) 
```




#negative binomial
```{r}
#autoplot(repeat_dn.negabin,which = 1:6, ncol = 3, label.size = 3,shape = 1, alpha = 0.7) 

```

#quasi-poisson
```{r}
autoplot(repeat_dn.qpoisson,which = 1:6, ncol = 3, label.size = 3,shape = 1, alpha = 0.7)
```


```{r}
plot(repeat_dn.poisson, which = 3)

```

```{r}
#plot(repeat_dn.negabin, which = 3)
```

```{r}
plot(repeat_dn.qpoisson, which = 3)

```

#regression tables 
```{r}
summary(repeat_dn.poisson)
```

```{r}
#summary(repeat_dn.negabin)
```

```{r}
summary(repeat_dn.qpoisson)
```


#New donors autoplots
```{r}

autoplot(new_dn.poisson,which = 1:6, ncol = 3, label.size = 3,shape = 1, alpha = 0.7)
```


```{r}

#autoplot(new_dn.negabin,which = 1:6, ncol = 3, label.size = 3,shape = 1, alpha = 0.7)
```

```{r}
autoplot(new_dn.qpoisson,which = 1:6, ncol = 3, label.size = 3,shape = 1, alpha = 0.7)
```


#new donor regression tables 
```{r}
summary(new_dn.poisson)

```

```{r}
#summary(new_dn.negabin)
```

```{r}

summary(new_dn.qpoisson)


```



#Stargazer  for regression tables 
```{r} 
# filtered the negative binomial out for not suitable for data 
stargazer(repeat_dn.poisson,repeat_dn.qpoisson,new_dn.poisson,new_dn.qpoisson,intercept.bottom = FALSE,
          type = "html",
single.row = TRUE,
          ci = TRUE,
          omit = "Constant",
          header = FALSE,
          covariate.labels = c(),
         column.labels = c("Repeat donors","First time donors","Repeat donors","First time donors"),
          #dep.var.caption   = "", 
          dep.var.labels.include = FALSE,
          # column.labels = c("
          star.cutoffs = c(0.05, 0.01, 0.001) ,
         out="regression.table.htm")
        
        

```


#Scaling the regressors

```{r}

sc_data <- modified_data %>% mutate(higher_education= scale(proportion_inhabitants_with_higher_education,scale=TRUE)[,1],
                eligible_population= scale(eligible_population,scale=TRUE)[,1],
                medianincome = scale(medianincome,scale=TRUE)[,1],
                minDistkm. = scale((minDistkm),scale=TRUE)[,1])
              
```




```{r,warning=FALSE}
repeat_donor_poisson <- glm(prop_repeat_donors ~ medianincome + higher_education + eligible_population + minDistkm, data=sc_data,family=poisson)  #repeated donors
new_donor_poisson <- glm(prop_new_donors ~ medianincome + higher_education + eligible_population + minDistkm, data=sc_data, family=poisson)#new donors

# Lets make binomial model for comparison 
#repeat_dn.negabin <- MASS::glm.nb(prop_repea_tdonors ~ medianincome + higher_education + eligible_population + minDistkm, data=data)
#new_dn.negabin<-MASS::glm.nb(prop_new_donors ~ medianincome + higher_education + eligible_population + minDistkm, data=data)

#quasipoisson
repeat_donor_qpoisson <- glm(prop_repeat_donors ~ medianincome + higher_education + eligible_population + minDistkm, data=sc_data,family=quasipoisson)  
new_donor_qpoisson <- glm(prop_new_donors ~ medianincome + higher_education + eligible_population + minDistkm, data=sc_data, family=quasipoisson)
```



#scaling drops the standard error a lot

```{r}
summary(repeat_donor_poisson)
```


```{r}
summary(repeat_donor_qpoisson)
```

```{r,warning=FALSE}
summary(repeat_donor_qpoisson)
```
```{r,warning=FALSE}
avPlots(repeat_donor_poisson)
```



```{r,warning= FALSE}
avPlots(repeat_donor_qpoisson)
```

```{r,warning=FALSE}
avPlots(new_donor_poisson)
```

```{r}
avPlots(new_donor_qpoisson)
```




Overdispersion is a situation where the residual deviance of the glm is large relative to the residual degrees of freedom.  These values are shown in the summary of the model.  One guideline is that if the ratio of the residual deviance to the residual degrees of freedom exceeds 1.5, then the model is overdispersed.  Overdispersion indicates that the model doesnâ€™t fit the data well:  the explanatory variables may not well describe the dependent variable or the model may not be specified correctly for these data.  If there is overdispersion, one potential solution is to use the quasibinomial family option in glm.


```{r}
summary(repeat_donor_poisson$deviance/summary(repeat_donor_poisson$df.residual))
mean(sc_data$prop_donors)
var(sc_data$prop_donors)
```

This parameter tells us how many times larger the variance is than the mean. Since our dispersion was less than one, it turns out the conditional variance is actually smaller than the conditional mean. We have under-dispersion, not over.




```{r}
dispersiontest(repeat_dn.poisson)
dispersiontest(repeat_donor_poisson)
dispersiontest(new_dn.poisson)
dispersiontest(new_donor_poisson)
```
Underdispersion is less common but is allowed in quasi-maximum likelihood estimation (QMLE) (Woolridge 2014, 481)




#prediction diagnostics for poisson and quasi-poisson with scaled data
plot the predicted values versus the observed values for these same datasets.

The most useful way to plot the residuals, though, is with your predicted values on the x-axis, and your residuals on the y-axis.



```{r,message=FALSE}
modelr::spread_predictions(sc_data, repeat_donor_poisson, repeat_donor_qpoisson, new_donor_poisson,new_donor_qpoisson)
```







#Robust poisson regression

```{r,warning=FALSE}
robust_repeat_poisson <- glmrob(prop_repeat_donors ~ medianincome + higher_education + eligible_population + minDistkm, data=sc_data,family=poisson)  #repeated donors
robust_new_poisson <- glmrob(prop_new_donors ~ medianincome + higher_education + eligible_population + minDistkm, data=sc_data, family=poisson)#new donors


```

## Stargazer for robust, poisson and quasipoisson models. 

```{r}
stargazer(repeat_donor_poisson, new_donor_poisson, robust_repeat_poisson, robust_new_poisson,repeat_donor_qpoisson, new_donor_qpoisson, intercept.bottom = TRUE,
          type = "latex",
single.row = TRUE,
          ci = TRUE,
          omit = "Constant",
          header = FALSE,
          covariate.labels = c("Median income", "Higher education", "eligible population", "minimum distance km"),
         column.labels = c("Repeat donors","First time donors","Repeat donors","First time donors", "Repeat donors", "First time donors"),
          #dep.var.caption   = "BMI", 
          dep.var.labels.include = FALSE,
       out="robustandscaled.rtable.htm")
        
```


```{r,warning=FALSE}

#stargazer(repeat_donor_poisson,new_donor_poisson, robust_repeat_poisson,robust_new_poisson,repeat_donor_qpoisson,new_donor_qpoisson,repeat_donor_quasibino,new_donor_quasibino, intercept.bottom = TRUE,
#          type = "html",
#single.row = TRUE,
 #         ci = TRUE,
 #         omit = "Constant",
  #        header = FALSE,
   #       covariate.labels = c("Median income", "Higher education", "eligible population", "minimum distance km"),
    #     column.labels = c("Repeat donors","First time donors","Repeat donors","First time donors", "Repeat donors", "First time donors", "Repeat donors", "First time donors"),
          #dep.var.caption   = "BMI", 
    #      dep.var.labels.include = FALSE,
     ##  out="robustandscaled.rtable.htm")
        
```

##Stargazer for quasipoisson model 
```{r}
stargazer(repeat_donor_qpoisson,new_donor_qpoisson,robust_new_poisson,robust_repeat_poisson,
          intercept.bottom = TRUE,
          type = "html",
single.row = TRUE,
          ci = TRUE,
          omit = "Constant",
          header = FALSE,
          covariate.labels = c("Median income", "Higher education", "eligible population", "minimum distance"),
         column.labels = c("Repeat donors","First time donors"),
          #dep.var.caption   = "BMI", 
          dep.var.labels.include = FALSE,
       out="quasipoisson.rtable.html")
```

##Prediction diagnostics for robust poisson regression 

```{r}
                 
                 
```



#comparing 

#quasibinomial
```{r}
#repeat_donor_quasibino<- glm(prop_repeat_donors ~ medianincome + higher_education + eligible_population + minDistkm, data=sc_data,family= quasibinomial)

#new_donor_quasibino <-  glm(prop_new_donors ~ medianincome + higher_education + eligible_population + minDistkm, data=sc_data,family= quasibinomial)
```

Quasipoisson models are not likelihood based. They maximize a "quasilikelihood" which is a Poisson likelihood up to a proportional constant. That proportional constant happens to be the dispersion. The dispersion is considered a nuisance parameter. While the maximization routine comes up with an estimate of the nuisance parameter, that estimate is merely an artifact of the data rather than any value which generalizes to the population. The dispersion only serves to "shrink" or "widen" the SEs of the regression parameters according to whether the variance is proportionally smaller than or larger than the mean. Since the dispersion is treated as a nuisance parameter, quasipoisson models enjoy a host of robust properties: the data can in fact be heteroscedastic (not meeting the proportional mean-variance assumption) and even exhibit small sources of dependence, and the mean model need not be exactly correct, but the 95% CIs for the regression parameters are asymptotically correct. If your goal of the data analysis is to measure the association between a set of regression parameters and the outcome, quasipoisson models are usually the way to go. A limitation of these models is that they cannot yield prediction intervals, the Pearson residuals cannot tell you much about how accurate the mean model is, and information criteria like the AIC or BIC cannot effectively compare these models to other types of models.


```{r}
summary(repeat_donor_qpoisson)
summary(new_donor_qpoisson)
summary(robust_repeat_poisson)
summary(robust_new_poisson)
```

# Predictions 
```{r}

```


    

Voisit kÃ¤yttÃ¤Ã¤ pari slidea siihen, ettÃ¤ selitÃ¤t mitÃ¤ ovat mallin virheet, kuva sun mallin virheistÃ¤ olisi hyvÃ¤ ja sitten kÃ¤yt lÃ¤pi ne jakauma vaihtoehdot ja ehkÃ¤ jopa piirrÃ¤t jakauma vaihtoehdot mallin virheiden pÃ¤Ã¤lle. Virhejakauman muodon valinta on kuitenkin tÃ¤ssÃ¤ yksi tÃ¤rkeimpiÃ¤ asioita.


conway-maxwell poisson regression 

```{r}
library(COMPoissonReg)


```
Ideally plot the predicted effect over time along with 95% CIs, since the last sentence is too technical for non-statistical reviewers.


Yet another approach would be to take the absolute values of, in your model, the Z-statistics, sum them up and then repercentage each abs parameter with that total. By ranking those relativized percentages, a viable heuristic for relative importance can be easily obtained.

Given that the Poisson and Logit model differ, in terms of the Generalized Linear Model, only in their link function (log as opposed to logit) and probability distribution (Poisson as opposed to Bernoulli), the solutions applied to the logit regression should hold on Poisson regression when changing these two model specifications.




underdispersion is the opposite of overdispersion. Underdispersion exists when data exhibit less variation than you would expect based on a binomial distribution (for defectives) or a Poisson distribution (for defects). Underdispersion can occur when adjacent subgroups are correlated with each other, also known as autocorrelation.

When data exhibit underdispersion, the control limits on a traditional P chart or U chart may be too wide. If the control limits are too wide, you can overlook special-cause variation and mistake it for common-cause variation. If there is underdispersion, the control limits on a Laney attributes chart are narrower than those of a traditional attributes chart.

For example, as a tool wears out, the number of defects may increase. The increase in defect counts across subgroups can make the subgroups more similar than they would be by chance. 


autocorrelation




#bootstrapping
 great advantage of bootstrap is its simplicity. It is a straightforward way to derive estimates of standard errors and confidence intervals for complex estimators of complex parameters of the distribution, such as percentile points, proportions, odds ratio, and correlation coefficients. Bootstrap is also an appropriate way to control and check the stability of the results. Although for most problems it is impossible to know the true confidence interval, bootstrap is asymptotically more accurate than the standard intervals obtained using sample variance and assumptions of normality.[16]
    


          